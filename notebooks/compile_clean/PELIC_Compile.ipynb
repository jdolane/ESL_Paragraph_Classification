{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb14e845",
   "metadata": {},
   "source": [
    "# Compile the PELIC Dataset\n",
    "This notebook is to compile and clean the PELIC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca8a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82c41e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to be using this to process the data later on, so I'll load it now.\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e616d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path\n",
    "path = '../data/PELIC-dataset/corpus_files/'\n",
    "# Read the data\n",
    "question = pd.read_csv(path + 'question.csv')\n",
    "answer = pd.read_csv(path + 'answer.csv')\n",
    "student_info = pd.read_csv(path + 'student_information.csv')\n",
    "course = pd.read_csv(path + 'course.csv')\n",
    "scores = pd.read_csv(path + 'test_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7a07c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on 'question_id' and 'anon_id'\n",
    "merged_df = pd.merge(answer, question, on='question_id', how='left')\n",
    "merged_df = pd.merge(merged_df, student_info, on='anon_id', how='left')\n",
    "merged_df = pd.merge(merged_df, course, on='course_id', how='left')\n",
    "merged_df = pd.merge(merged_df, scores, on='anon_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b90c3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some columns to maintain consistency with other data sets\n",
    "merged_df.rename(columns={'stem': 'question'}, inplace=True)\n",
    "merged_df.rename(columns={'text': 'answer'}, inplace=True)\n",
    "merged_df.rename(columns={'native_language': 'L1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34a73db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the question types\n",
    "question_type_mapping = {\n",
    "    1: 'Paragraph writing',\n",
    "    2: 'Short answer',\n",
    "    3: 'Multiple choice',\n",
    "    4: 'Essay',\n",
    "    5: 'Fill-in-the-blank',\n",
    "    6: 'Sentence completion',\n",
    "    7: 'Word bank',\n",
    "    8: 'Chart',\n",
    "    9: 'Word selection',\n",
    "    10: 'Audio recording'\n",
    "}\n",
    "\n",
    "# Create the new 'question_type' column by mapping 'question_type_id' using the mapping dictionary\n",
    "merged_df['question_type'] = merged_df['question_type_id'].map(question_type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "098665d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47667 entries, 0 to 47666\n",
      "Data columns (total 47 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   answer_id                   47667 non-null  int64  \n",
      " 1   question_id                 47667 non-null  int64  \n",
      " 2   anon_id                     47667 non-null  object \n",
      " 3   course_id                   47667 non-null  int64  \n",
      " 4   version                     47667 non-null  int64  \n",
      " 5   created_date                47667 non-null  object \n",
      " 6   text_len                    47667 non-null  int64  \n",
      " 7   answer                      47664 non-null  object \n",
      " 8   tokens                      47667 non-null  object \n",
      " 9   tok_lem_POS                 47667 non-null  object \n",
      " 10  question_type_id            47538 non-null  float64\n",
      " 11  question                    47241 non-null  object \n",
      " 12  allow_text                  47538 non-null  float64\n",
      " 13  gender                      47667 non-null  object \n",
      " 14  birth_year                  38601 non-null  float64\n",
      " 15  L1                          47667 non-null  object \n",
      " 16  language_used_at_home       38590 non-null  object \n",
      " 17  non_native_language_1       37567 non-null  object \n",
      " 18  yrs_of_study_lang1          37688 non-null  object \n",
      " 19  study_in_classroom_lang1    37688 non-null  object \n",
      " 20  ways_of_study_lang1         37688 non-null  object \n",
      " 21  non_native_language_2       12746 non-null  object \n",
      " 22  yrs_of_study_lang2          12831 non-null  object \n",
      " 23  study_in_classroom_lang2    37688 non-null  object \n",
      " 24  ways_of_study_lang2         12831 non-null  object \n",
      " 25  non_native_language_3       1983 non-null   object \n",
      " 26  yrs_of_study_lang3          2377 non-null   object \n",
      " 27  study_in_classroom_lang3    37688 non-null  object \n",
      " 28  ways_of_study_lang3         2377 non-null   object \n",
      " 29  course_history              38601 non-null  object \n",
      " 30  yrs_of_english_learning     38547 non-null  object \n",
      " 31  yrs_in_english_environment  38547 non-null  object \n",
      " 32  age                         38601 non-null  float64\n",
      " 33  class_id                    47667 non-null  object \n",
      " 34  level_id                    47667 non-null  int64  \n",
      " 35  semester_x                  47667 non-null  object \n",
      " 36  section                     47667 non-null  object \n",
      " 37  semester_y                  45536 non-null  object \n",
      " 38  LCT_Form                    37741 non-null  float64\n",
      " 39  LCT_Score                   45610 non-null  float64\n",
      " 40  MTELP_Form                  35801 non-null  object \n",
      " 41  MTELP_I                     45610 non-null  float64\n",
      " 42  MTELP_II                    45610 non-null  float64\n",
      " 43  MTELP_III                   45610 non-null  float64\n",
      " 44  MTELP_Conv_Score            45610 non-null  float64\n",
      " 45  Writing_Sample              45610 non-null  float64\n",
      " 46  question_type               47538 non-null  object \n",
      "dtypes: float64(11), int64(6), object(30)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Look at the columns, their types, and which columns have null values\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07f1f592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "version\n",
       "1    42916\n",
       "2     4154\n",
       "3      597\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at how many questions there are of each version\n",
    "merged_df.version.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb040e7",
   "metadata": {},
   "source": [
    "The 'version' column indicates that there are different versions of the text; however, I can't find the difference between the versions. Instead of choosing a version, we're going to filter out duplicate answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01ec5306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>version</th>\n",
       "      <th>created_date</th>\n",
       "      <th>text_len</th>\n",
       "      <th>answer</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS</th>\n",
       "      <th>...</th>\n",
       "      <th>semester_y</th>\n",
       "      <th>LCT_Form</th>\n",
       "      <th>LCT_Score</th>\n",
       "      <th>MTELP_Form</th>\n",
       "      <th>MTELP_I</th>\n",
       "      <th>MTELP_II</th>\n",
       "      <th>MTELP_III</th>\n",
       "      <th>MTELP_Conv_Score</th>\n",
       "      <th>Writing_Sample</th>\n",
       "      <th>question_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>gc5</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-21 10:24:26</td>\n",
       "      <td>102</td>\n",
       "      <td>Last week I planned to go paintball match' but...</td>\n",
       "      <td>['Last', 'week', 'I', 'planned', 'to', 'go', '...</td>\n",
       "      <td>[('Last', 'last', 'JJ'), ('week', 'week', 'NN'...</td>\n",
       "      <td>...</td>\n",
       "      <td>2006_fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>R</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Paragraph writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>gc5</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-21 10:24:26</td>\n",
       "      <td>102</td>\n",
       "      <td>Last week I planned to go paintball match' but...</td>\n",
       "      <td>['Last', 'week', 'I', 'planned', 'to', 'go', '...</td>\n",
       "      <td>[('Last', 'last', 'JJ'), ('week', 'week', 'NN'...</td>\n",
       "      <td>...</td>\n",
       "      <td>2007_spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>R</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Paragraph writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>492</td>\n",
       "      <td>44</td>\n",
       "      <td>gc5</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-10-02 11:49:16</td>\n",
       "      <td>49</td>\n",
       "      <td>screw, interval, concurrent, dence anticipate,...</td>\n",
       "      <td>['screw', ',', 'interval', ',', 'concurrent', ...</td>\n",
       "      <td>[('screw', 'screw', 'NN'), (',', ',', ','), ('...</td>\n",
       "      <td>...</td>\n",
       "      <td>2006_fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>R</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Short answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>492</td>\n",
       "      <td>44</td>\n",
       "      <td>gc5</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-10-02 11:49:16</td>\n",
       "      <td>49</td>\n",
       "      <td>screw, interval, concurrent, dence anticipate,...</td>\n",
       "      <td>['screw', ',', 'interval', ',', 'concurrent', ...</td>\n",
       "      <td>[('screw', 'screw', 'NN'), (',', ',', ','), ('...</td>\n",
       "      <td>...</td>\n",
       "      <td>2007_spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>R</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Short answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1140</td>\n",
       "      <td>107</td>\n",
       "      <td>gc5</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-10-17 10:40:25</td>\n",
       "      <td>258</td>\n",
       "      <td>Limiting students on-line time may be seem a g...</td>\n",
       "      <td>['Limiting', 'students', 'on-line', 'time', 'm...</td>\n",
       "      <td>[('Limiting', 'limit', 'VBG'), ('students', 's...</td>\n",
       "      <td>...</td>\n",
       "      <td>2006_fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>R</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Paragraph writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1140</td>\n",
       "      <td>107</td>\n",
       "      <td>gc5</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-10-17 10:40:25</td>\n",
       "      <td>258</td>\n",
       "      <td>Limiting students on-line time may be seem a g...</td>\n",
       "      <td>['Limiting', 'students', 'on-line', 'time', 'm...</td>\n",
       "      <td>[('Limiting', 'limit', 'VBG'), ('students', 's...</td>\n",
       "      <td>...</td>\n",
       "      <td>2007_spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>R</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Paragraph writing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      answer_id  question_id anon_id  course_id  version         created_date  \\\n",
       "24           25           10     gc5        114        1  2006-09-21 10:24:26   \n",
       "25           25           10     gc5        114        1  2006-09-21 10:24:26   \n",
       "454         492           44     gc5        102        1  2006-10-02 11:49:16   \n",
       "455         492           44     gc5        102        1  2006-10-02 11:49:16   \n",
       "1097       1140          107     gc5        114        1  2006-10-17 10:40:25   \n",
       "1098       1140          107     gc5        114        1  2006-10-17 10:40:25   \n",
       "\n",
       "      text_len                                             answer  \\\n",
       "24         102  Last week I planned to go paintball match' but...   \n",
       "25         102  Last week I planned to go paintball match' but...   \n",
       "454         49  screw, interval, concurrent, dence anticipate,...   \n",
       "455         49  screw, interval, concurrent, dence anticipate,...   \n",
       "1097       258  Limiting students on-line time may be seem a g...   \n",
       "1098       258  Limiting students on-line time may be seem a g...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "24    ['Last', 'week', 'I', 'planned', 'to', 'go', '...   \n",
       "25    ['Last', 'week', 'I', 'planned', 'to', 'go', '...   \n",
       "454   ['screw', ',', 'interval', ',', 'concurrent', ...   \n",
       "455   ['screw', ',', 'interval', ',', 'concurrent', ...   \n",
       "1097  ['Limiting', 'students', 'on-line', 'time', 'm...   \n",
       "1098  ['Limiting', 'students', 'on-line', 'time', 'm...   \n",
       "\n",
       "                                            tok_lem_POS  ...   semester_y  \\\n",
       "24    [('Last', 'last', 'JJ'), ('week', 'week', 'NN'...  ...    2006_fall   \n",
       "25    [('Last', 'last', 'JJ'), ('week', 'week', 'NN'...  ...  2007_spring   \n",
       "454   [('screw', 'screw', 'NN'), (',', ',', ','), ('...  ...    2006_fall   \n",
       "455   [('screw', 'screw', 'NN'), (',', ',', ','), ('...  ...  2007_spring   \n",
       "1097  [('Limiting', 'limit', 'VBG'), ('students', 's...  ...    2006_fall   \n",
       "1098  [('Limiting', 'limit', 'VBG'), ('students', 's...  ...  2007_spring   \n",
       "\n",
       "     LCT_Form  LCT_Score MTELP_Form  MTELP_I MTELP_II MTELP_III  \\\n",
       "24        1.0       21.0          R     16.0     19.0       6.0   \n",
       "25        1.0       24.0          R     15.0     16.0       7.0   \n",
       "454       1.0       21.0          R     16.0     19.0       6.0   \n",
       "455       1.0       24.0          R     15.0     16.0       7.0   \n",
       "1097      1.0       21.0          R     16.0     19.0       6.0   \n",
       "1098      1.0       24.0          R     15.0     16.0       7.0   \n",
       "\n",
       "     MTELP_Conv_Score Writing_Sample      question_type  \n",
       "24               60.0            2.6  Paragraph writing  \n",
       "25               57.0            3.0  Paragraph writing  \n",
       "454              60.0            2.6       Short answer  \n",
       "455              57.0            3.0       Short answer  \n",
       "1097             60.0            2.6  Paragraph writing  \n",
       "1098             57.0            3.0  Paragraph writing  \n",
       "\n",
       "[6 rows x 47 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicate answer_id\n",
    "duplicates = merged_df[merged_df.duplicated('answer_id', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "duplicates.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5a5cf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last week I planned to go paintball match' but I lived a healthy problem. I had hard lumbago last days. Therfore I asked my brother could you go instead of me? He accepted my order and he went paintball area yesterday, but yesterday was rainy and cold. On the other hand the other players who all of arabic spoked between native language. My brother didn't understand nothing what they spoked. Even if he played this game, he hadn't a good time. He came to home with funny statue. All wears was coloured and wet. He slept very well last night.\n",
      "\n",
      "\n",
      "Last week I planned to go paintball match' but I lived a healthy problem. I had hard lumbago last days. Therfore I asked my brother could you go instead of me? He accepted my order and he went paintball area yesterday, but yesterday was rainy and cold. On the other hand the other players who all of arabic spoked between native language. My brother didn't understand nothing what they spoked. Even if he played this game, he hadn't a good time. He came to home with funny statue. All wears was coloured and wet. He slept very well last night.\n"
     ]
    }
   ],
   "source": [
    "# We can see above and below that there appears to be no difference between the two versions\n",
    "print(merged_df[merged_df.answer_id == 25].answer[24])\n",
    "print('\\n')\n",
    "print(merged_df[merged_df.answer_id == 25].answer[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c930359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>version</th>\n",
       "      <th>created_date</th>\n",
       "      <th>text_len</th>\n",
       "      <th>answer</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS</th>\n",
       "      <th>...</th>\n",
       "      <th>semester_y</th>\n",
       "      <th>LCT_Form</th>\n",
       "      <th>LCT_Score</th>\n",
       "      <th>MTELP_Form</th>\n",
       "      <th>MTELP_I</th>\n",
       "      <th>MTELP_II</th>\n",
       "      <th>MTELP_III</th>\n",
       "      <th>MTELP_Conv_Score</th>\n",
       "      <th>Writing_Sample</th>\n",
       "      <th>question_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-20 16:11:08</td>\n",
       "      <td>177</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>['I', 'met', 'my', 'friend', 'Nife', 'while', ...</td>\n",
       "      <td>[('I', 'I', 'PRP'), ('met', 'meet', 'VBD'), ('...</td>\n",
       "      <td>...</td>\n",
       "      <td>2006_spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>P</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Paragraph writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-20 22:09:14</td>\n",
       "      <td>137</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>['Ten', 'years', 'ago', ',', 'I', 'met', 'a', ...</td>\n",
       "      <td>[('Ten', 'ten', 'CD'), ('years', 'year', 'NNS'...</td>\n",
       "      <td>...</td>\n",
       "      <td>2006_spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>P</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Paragraph writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>dk5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-21 10:16:17</td>\n",
       "      <td>63</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>['In', 'my', 'country', 'we', 'usually', 'do',...</td>\n",
       "      <td>[('In', 'in', 'IN'), ('my', 'my', 'PRP$'), ('c...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paragraph writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>dk5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-21 10:16:17</td>\n",
       "      <td>6</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>['I', 'organized', 'the', 'instructions', 'by'...</td>\n",
       "      <td>[('I', 'I', 'PRP'), ('organized', 'organize', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paragraph writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-21 10:19:01</td>\n",
       "      <td>59</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\nSe...</td>\n",
       "      <td>['First', ',', 'prepare', 'a', 'port', ',', 'l...</td>\n",
       "      <td>[('First', 'first', 'RB'), (',', ',', ','), ('...</td>\n",
       "      <td>...</td>\n",
       "      <td>2006_summer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>R</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Paragraph writing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_id  question_id anon_id  course_id  version         created_date  \\\n",
       "0          1            5     eq0        149        1  2006-09-20 16:11:08   \n",
       "1          2            5     am8        149        1  2006-09-20 22:09:14   \n",
       "2          3           12     dk5        115        1  2006-09-21 10:16:17   \n",
       "3          4           13     dk5        115        1  2006-09-21 10:16:17   \n",
       "4          5           12     ad1        115        1  2006-09-21 10:19:01   \n",
       "\n",
       "   text_len                                             answer  \\\n",
       "0       177  I met my friend Nife while I was studying in a...   \n",
       "1       137  Ten years ago, I met a women on the train betw...   \n",
       "2        63  In my country we usually don't use tea bags. F...   \n",
       "3         6              I organized the instructions by time.   \n",
       "4        59  First, prepare a port, loose tea, and cup.\\nSe...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['I', 'met', 'my', 'friend', 'Nife', 'while', ...   \n",
       "1  ['Ten', 'years', 'ago', ',', 'I', 'met', 'a', ...   \n",
       "2  ['In', 'my', 'country', 'we', 'usually', 'do',...   \n",
       "3  ['I', 'organized', 'the', 'instructions', 'by'...   \n",
       "4  ['First', ',', 'prepare', 'a', 'port', ',', 'l...   \n",
       "\n",
       "                                         tok_lem_POS  ...   semester_y  \\\n",
       "0  [('I', 'I', 'PRP'), ('met', 'meet', 'VBD'), ('...  ...  2006_spring   \n",
       "1  [('Ten', 'ten', 'CD'), ('years', 'year', 'NNS'...  ...  2006_spring   \n",
       "2  [('In', 'in', 'IN'), ('my', 'my', 'PRP$'), ('c...  ...          NaN   \n",
       "3  [('I', 'I', 'PRP'), ('organized', 'organize', ...  ...          NaN   \n",
       "4  [('First', 'first', 'RB'), (',', ',', ','), ('...  ...  2006_summer   \n",
       "\n",
       "  LCT_Form  LCT_Score MTELP_Form  MTELP_I MTELP_II MTELP_III MTELP_Conv_Score  \\\n",
       "0      1.0        5.0          P      5.0      7.0       0.0             28.0   \n",
       "1      1.0       11.0          P     15.0      9.0       5.0             45.0   \n",
       "2      NaN        NaN        NaN      NaN      NaN       NaN              NaN   \n",
       "3      NaN        NaN        NaN      NaN      NaN       NaN              NaN   \n",
       "4      1.0       23.0          R     22.0     30.0      14.0             81.0   \n",
       "\n",
       "  Writing_Sample      question_type  \n",
       "0            1.0  Paragraph writing  \n",
       "1            2.3  Paragraph writing  \n",
       "2            NaN  Paragraph writing  \n",
       "3            NaN  Paragraph writing  \n",
       "4            2.0  Paragraph writing  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find unique answer values\n",
    "unique_answers = merged_df['answer'].value_counts() == 1\n",
    "\n",
    "# Get the index of unique answer values\n",
    "unique_index = unique_answers[unique_answers].index\n",
    "\n",
    "# Filter the DataFrame to keep only rows with unique answer values\n",
    "unique_df = merged_df[merged_df['answer'].isin(unique_index)]\n",
    "\n",
    "unique_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "956baba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>version</th>\n",
       "      <th>created_date</th>\n",
       "      <th>text_len</th>\n",
       "      <th>answer</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS</th>\n",
       "      <th>...</th>\n",
       "      <th>semester_y</th>\n",
       "      <th>LCT_Form</th>\n",
       "      <th>LCT_Score</th>\n",
       "      <th>MTELP_Form</th>\n",
       "      <th>MTELP_I</th>\n",
       "      <th>MTELP_II</th>\n",
       "      <th>MTELP_III</th>\n",
       "      <th>MTELP_Conv_Score</th>\n",
       "      <th>Writing_Sample</th>\n",
       "      <th>question_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [answer_id, question_id, anon_id, course_id, version, created_date, text_len, answer, tokens, tok_lem_POS, question_type_id, question, allow_text, gender, birth_year, L1, language_used_at_home, non_native_language_1, yrs_of_study_lang1, study_in_classroom_lang1, ways_of_study_lang1, non_native_language_2, yrs_of_study_lang2, study_in_classroom_lang2, ways_of_study_lang2, non_native_language_3, yrs_of_study_lang3, study_in_classroom_lang3, ways_of_study_lang3, course_history, yrs_of_english_learning, yrs_in_english_environment, age, class_id, level_id, semester_x, section, semester_y, LCT_Form, LCT_Score, MTELP_Form, MTELP_I, MTELP_II, MTELP_III, MTELP_Conv_Score, Writing_Sample, question_type]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 47 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check to make sure that there are no more duplicate answer_ids, now that we've removed\n",
    "# the duplicate answers\n",
    "# Find duplicate answer_id\n",
    "duplicates = unique_df[unique_df.duplicated('answer_id', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "duplicates.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ab0bb",
   "metadata": {},
   "source": [
    "Some columns contain a high number of null values, but we don't want to lose data when we drop NA values. First, we're going to filter out the data that we want to use, and then We're going to select the columns that we're interested in and put them into a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c5de9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_id\n",
       "w    13098\n",
       "r    12651\n",
       "g    10267\n",
       "l      889\n",
       "s       37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firstly, let's look at the class (course) types\n",
    "unique_df.class_id.value_counts()\n",
    "# w = writing\n",
    "# r = reading\n",
    "# g = grammar\n",
    "# l = listesing\n",
    "# s = speaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "62341daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allow_text                    0.0   1.0\n",
      "class_id question_type                 \n",
      "g        Audio recording        0     1\n",
      "         Essay                  0    55\n",
      "         Fill-in-the-blank      0   423\n",
      "         Paragraph writing      0  6410\n",
      "         Sentence completion    0   423\n",
      "         Short answer           0  2955\n",
      "l        Essay                  0    39\n",
      "         Paragraph writing      0   582\n",
      "         Short answer          56   200\n",
      "r        Essay                  0   104\n",
      "         Fill-in-the-blank     11     0\n",
      "         Paragraph writing      0  3423\n",
      "         Short answer         233  8861\n",
      "         Word bank              7     0\n",
      "s        Short answer           0    37\n",
      "w        Essay                  0  3136\n",
      "         Paragraph writing      0  5190\n",
      "         Short answer           0  4759\n"
     ]
    }
   ],
   "source": [
    "# Look at the question types for each type of class\n",
    "writing_question_types = unique_df.groupby(['class_id', 'question_type'])['allow_text'].value_counts().unstack(fill_value=0)\n",
    "print(writing_question_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e825efc",
   "metadata": {},
   "source": [
    "Answers from every class type allow for open answers, so we can keep data from all class types. The short answer question type has open-text answers as well as non-open-text answers (e.g., multiple choice). So, the most logical thing to do here is simply to drop all answers that don't allow for open text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a3a4d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conserve open-text answers\n",
    "unique_df = unique_df[unique_df.allow_text == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ebe748d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 36598 entries, 0 to 47662\n",
      "Data columns (total 47 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   answer_id                   36598 non-null  int64  \n",
      " 1   question_id                 36598 non-null  int64  \n",
      " 2   anon_id                     36598 non-null  object \n",
      " 3   course_id                   36598 non-null  int64  \n",
      " 4   version                     36598 non-null  int64  \n",
      " 5   created_date                36598 non-null  object \n",
      " 6   text_len                    36598 non-null  int64  \n",
      " 7   answer                      36598 non-null  object \n",
      " 8   tokens                      36598 non-null  object \n",
      " 9   tok_lem_POS                 36598 non-null  object \n",
      " 10  question_type_id            36598 non-null  float64\n",
      " 11  question                    36304 non-null  object \n",
      " 12  allow_text                  36598 non-null  float64\n",
      " 13  gender                      36598 non-null  object \n",
      " 14  birth_year                  29133 non-null  float64\n",
      " 15  L1                          36598 non-null  object \n",
      " 16  language_used_at_home       29122 non-null  object \n",
      " 17  non_native_language_1       28257 non-null  object \n",
      " 18  yrs_of_study_lang1          28346 non-null  object \n",
      " 19  study_in_classroom_lang1    28346 non-null  object \n",
      " 20  ways_of_study_lang1         28346 non-null  object \n",
      " 21  non_native_language_2       9885 non-null   object \n",
      " 22  yrs_of_study_lang2          9907 non-null   object \n",
      " 23  study_in_classroom_lang2    28346 non-null  object \n",
      " 24  ways_of_study_lang2         9907 non-null   object \n",
      " 25  non_native_language_3       1647 non-null   object \n",
      " 26  yrs_of_study_lang3          1991 non-null   object \n",
      " 27  study_in_classroom_lang3    28346 non-null  object \n",
      " 28  ways_of_study_lang3         1991 non-null   object \n",
      " 29  course_history              29133 non-null  object \n",
      " 30  yrs_of_english_learning     29089 non-null  object \n",
      " 31  yrs_in_english_environment  29089 non-null  object \n",
      " 32  age                         29133 non-null  float64\n",
      " 33  class_id                    36598 non-null  object \n",
      " 34  level_id                    36598 non-null  int64  \n",
      " 35  semester_x                  36598 non-null  object \n",
      " 36  section                     36598 non-null  object \n",
      " 37  semester_y                  34869 non-null  object \n",
      " 38  LCT_Form                    28299 non-null  float64\n",
      " 39  LCT_Score                   34941 non-null  float64\n",
      " 40  MTELP_Form                  26736 non-null  object \n",
      " 41  MTELP_I                     34941 non-null  float64\n",
      " 42  MTELP_II                    34941 non-null  float64\n",
      " 43  MTELP_III                   34941 non-null  float64\n",
      " 44  MTELP_Conv_Score            34941 non-null  float64\n",
      " 45  Writing_Sample              34941 non-null  float64\n",
      " 46  question_type               36598 non-null  object \n",
      "dtypes: float64(11), int64(6), object(30)\n",
      "memory usage: 13.4+ MB\n"
     ]
    }
   ],
   "source": [
    "unique_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d1263b",
   "metadata": {},
   "source": [
    "<p>Now, we need to drop null values from the dataset, but also conserve as much information that we're interested in as possible for both X and y values. Intuitively, it would seem that 'level_id' would be the best y; however, this is the level of the class that they student was in at the time of writing the answer - it doesn't necessarily indicate the level of the answer itself. Further, the level of the class doesn't line up neatly with a distinct CEFR level. We may be better off using one of the Michigan Test of English Language Proficiency (MTELP) scores, or the 'Writing Sample' column as our y.</p>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>level_id</th>\n",
    "        <th>Level description</th>\n",
    "        <th>CEFR level</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>Pre-Intermediate</td>\n",
    "        <td>A2/B1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>Intermediate</td>\n",
    "        <td>B1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>4</td>\n",
    "        <td>Upper-Intermediate</td>\n",
    "        <td>B1+/B2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>5</td>\n",
    "        <td>Advanced</td>\n",
    "        <td>B2+/C1</td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Column Name</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MTELP_I</td>\n",
    "        <td>Grammar section</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MTELP_II</td>\n",
    "        <td>Reading section</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MTELP_III</td>\n",
    "        <td>Listening section</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>MTELP_Conv_Score</td>\n",
    "        <td>Total combined score</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Writing_Sample</td>\n",
    "        <td>In-house writing test score (scale of 1-6)</td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br>\n",
    "<p>Since we need to keep the test score columns, we're going to drop anything that we don't need that has fewer than 34,941 non-null values. The only column below that value that I would consider keeping is the age column; however, for the purposes of the current project, I don't think it will be relevant.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5cb8808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 34660 entries, 0 to 47662\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   answer_id         34660 non-null  int64  \n",
      " 1   question_id       34660 non-null  int64  \n",
      " 2   anon_id           34660 non-null  object \n",
      " 3   course_id         34660 non-null  int64  \n",
      " 4   version           34660 non-null  int64  \n",
      " 5   created_date      34660 non-null  object \n",
      " 6   text_len          34660 non-null  int64  \n",
      " 7   answer            34660 non-null  object \n",
      " 8   tokens            34660 non-null  object \n",
      " 9   tok_lem_POS       34660 non-null  object \n",
      " 10  question_type_id  34660 non-null  float64\n",
      " 11  question          34660 non-null  object \n",
      " 12  allow_text        34660 non-null  float64\n",
      " 13  gender            34660 non-null  object \n",
      " 14  L1                34660 non-null  object \n",
      " 15  class_id          34660 non-null  object \n",
      " 16  level_id          34660 non-null  int64  \n",
      " 17  section           34660 non-null  object \n",
      " 18  MTELP_I           34660 non-null  float64\n",
      " 19  MTELP_II          34660 non-null  float64\n",
      " 20  MTELP_III         34660 non-null  float64\n",
      " 21  MTELP_Conv_Score  34660 non-null  float64\n",
      " 22  Writing_Sample    34660 non-null  float64\n",
      " 23  question_type     34660 non-null  object \n",
      "dtypes: float64(7), int64(6), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Select columns to keep\n",
    "columns_to_keep = ['answer_id', 'question_id', 'anon_id', 'course_id', 'version',\n",
    "       'created_date', 'text_len', 'answer', 'tokens', 'tok_lem_POS',\n",
    "       'question_type_id', 'question', 'allow_text', 'gender',\n",
    "       'L1', 'class_id', 'level_id', 'section', 'MTELP_I', 'MTELP_II',\n",
    "       'MTELP_III', 'MTELP_Conv_Score', 'Writing_Sample', 'question_type']\n",
    "\n",
    "# Put them in a new df\n",
    "df = unique_df[columns_to_keep].dropna()\n",
    "\n",
    "# Drop na values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0af439",
   "metadata": {},
   "source": [
    "Now we're going to filter out any answers that don't contain at least one subject and one verb. This will be our bare minimum criterion for text length, which will conserve data from the lower level classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e4fb2bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='int64')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, check if there are any answers that contain only empty space\n",
    "df.loc[df['answer'].str.isspace()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8b23d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the answer column is a string\n",
    "df['answer'] = df['answer'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ca7a23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to filter the data for answers that contain at least one subject and verb\n",
    "def contains_subject_and_verb(text):\n",
    "    '''\n",
    "    Checks to see if a document contains\n",
    "    at least one subject and one verb\n",
    "    '''\n",
    "    doc = nlp(text)\n",
    "    # Check if the text contains at least one subject and one verb\n",
    "    return any(token.dep_ == \"nsubj\" for token in doc) and any(token.pos_ == \"VERB\" for token in doc)\n",
    "\n",
    "def filter_rows_with_subject_and_verb(df):\n",
    "    '''\n",
    "    Applies the contains_subject_and_verb function\n",
    "    '''\n",
    "    # Apply the contains_subject_and_verb function to each row in the 'answer' column\n",
    "    mask = df['answer'].apply(contains_subject_and_verb)\n",
    "    # Filter the DataFrame to keep only the rows where the condition is True\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fff7db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "df = filter_rows_with_subject_and_verb(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3d235e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29631"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d4593",
   "metadata": {},
   "source": [
    "It looks like we eliminated 5,029 answers that don't contain at least one subject and one verb. Now, we're going to add columns for the number of sentences per text, the average sentence length, and the total number of tokens. These can be used in our y later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2e88041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of sentences per text,\n",
    "# and the average sentence length per text to the dataframe\n",
    "def sentence_length(df):\n",
    "    '''\n",
    "    Adds columns to the dataframe for the length of the answer,\n",
    "    the number of sentences per answer,\n",
    "    and the average sentence length per answer.\n",
    "    '''\n",
    "    # Load the English language model, if not already loaded at the top of the notebook\n",
    "#     nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # Create a copy of the DataFrame to avoid the SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    # Iterate over rows in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Get the answer text from the DataFrame\n",
    "        answer_text = row['answer']\n",
    "        # Process the answer text with spaCy\n",
    "        doc = nlp(answer_text)\n",
    "        # Initialize variables to accumulate total tokens and count of sentences\n",
    "        total_tokens = 0\n",
    "        num_sentences = 0\n",
    "\n",
    "        # Iterate over sentences and accumulate total tokens\n",
    "        for sentence in doc.sents:\n",
    "            num_tokens = len(sentence)\n",
    "            total_tokens += num_tokens\n",
    "            num_sentences += 1\n",
    "            \n",
    "        # Calculate the average sentence length\n",
    "        avg_len = total_tokens / num_sentences\n",
    "        # Add num_sentences and avg_len as new columns in the DataFrame\n",
    "        df.loc[index, 'num_sentences'] = num_sentences\n",
    "        df.loc[index, 'avg_sentence_length'] = avg_len\n",
    "        df.loc[index, 'total_tokens'] = total_tokens\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "05aeac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "df = sentence_length(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a436d035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>version</th>\n",
       "      <th>created_date</th>\n",
       "      <th>text_len</th>\n",
       "      <th>answer</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tok_lem_POS</th>\n",
       "      <th>...</th>\n",
       "      <th>section</th>\n",
       "      <th>MTELP_I</th>\n",
       "      <th>MTELP_II</th>\n",
       "      <th>MTELP_III</th>\n",
       "      <th>MTELP_Conv_Score</th>\n",
       "      <th>Writing_Sample</th>\n",
       "      <th>question_type</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>eq0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-20 16:11:08</td>\n",
       "      <td>177</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>['I', 'met', 'my', 'friend', 'Nife', 'while', ...</td>\n",
       "      <td>[('I', 'I', 'PRP'), ('met', 'meet', 'VBD'), ('...</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Paragraph writing</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.083333</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>am8</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-20 22:09:14</td>\n",
       "      <td>137</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>['Ten', 'years', 'ago', ',', 'I', 'met', 'a', ...</td>\n",
       "      <td>[('Ten', 'ten', 'CD'), ('years', 'year', 'NNS'...</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Paragraph writing</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>ad1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-21 10:19:01</td>\n",
       "      <td>59</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\n",
       "Sec...</td>\n",
       "      <td>['First', ',', 'prepare', 'a', 'port', ',', 'l...</td>\n",
       "      <td>[('First', 'first', 'RB'), (',', ',', ','), ('...</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Paragraph writing</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>eg5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-21 10:19:02</td>\n",
       "      <td>39</td>\n",
       "      <td>First, prepare your cup, loose tea or bag tea,...</td>\n",
       "      <td>['First', ',', 'prepare', 'your', 'cup', ',', ...</td>\n",
       "      <td>[('First', 'first', 'RB'), (',', ',', ','), ('...</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Paragraph writing</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>eg5</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-09-21 10:19:02</td>\n",
       "      <td>35</td>\n",
       "      <td>I organized the instructions by time, beacause...</td>\n",
       "      <td>['I', 'organized', 'the', 'instructions', 'by'...</td>\n",
       "      <td>[('I', 'I', 'PRP'), ('organized', 'organize', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Paragraph writing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_id  question_id anon_id  course_id  version         created_date  \\\n",
       "0          1            5     eq0        149        1  2006-09-20 16:11:08   \n",
       "1          2            5     am8        149        1  2006-09-20 22:09:14   \n",
       "4          5           12     ad1        115        1  2006-09-21 10:19:01   \n",
       "6          7           12     eg5        115        1  2006-09-21 10:19:02   \n",
       "7          8           13     eg5        115        1  2006-09-21 10:19:02   \n",
       "\n",
       "   text_len                                             answer  \\\n",
       "0       177  I met my friend Nife while I was studying in a...   \n",
       "1       137  Ten years ago, I met a women on the train betw...   \n",
       "4        59  First, prepare a port, loose tea, and cup.\n",
       "Sec...   \n",
       "6        39  First, prepare your cup, loose tea or bag tea,...   \n",
       "7        35  I organized the instructions by time, beacause...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['I', 'met', 'my', 'friend', 'Nife', 'while', ...   \n",
       "1  ['Ten', 'years', 'ago', ',', 'I', 'met', 'a', ...   \n",
       "4  ['First', ',', 'prepare', 'a', 'port', ',', 'l...   \n",
       "6  ['First', ',', 'prepare', 'your', 'cup', ',', ...   \n",
       "7  ['I', 'organized', 'the', 'instructions', 'by'...   \n",
       "\n",
       "                                         tok_lem_POS  ...  section MTELP_I  \\\n",
       "0  [('I', 'I', 'PRP'), ('met', 'meet', 'VBD'), ('...  ...        M     5.0   \n",
       "1  [('Ten', 'ten', 'CD'), ('years', 'year', 'NNS'...  ...        M    15.0   \n",
       "4  [('First', 'first', 'RB'), (',', ',', ','), ('...  ...        Q    22.0   \n",
       "6  [('First', 'first', 'RB'), (',', ',', ','), ('...  ...        Q    18.0   \n",
       "7  [('I', 'I', 'PRP'), ('organized', 'organize', ...  ...        Q    18.0   \n",
       "\n",
       "   MTELP_II MTELP_III MTELP_Conv_Score Writing_Sample      question_type  \\\n",
       "0       7.0       0.0             28.0            1.0  Paragraph writing   \n",
       "1       9.0       5.0             45.0            2.3  Paragraph writing   \n",
       "4      30.0      14.0             81.0            2.0  Paragraph writing   \n",
       "6      28.0      13.0             74.0            3.0  Paragraph writing   \n",
       "7      28.0      13.0             74.0            3.0  Paragraph writing   \n",
       "\n",
       "  num_sentences  avg_sentence_length  total_tokens  \n",
       "0          12.0            16.083333         193.0  \n",
       "1          10.0            15.600000         156.0  \n",
       "4           5.0            15.600000          78.0  \n",
       "6           4.0            13.500000          54.0  \n",
       "7           2.0            19.500000          39.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ac063d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29631 entries, 0 to 47662\n",
      "Data columns (total 27 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   answer_id            29631 non-null  int64  \n",
      " 1   question_id          29631 non-null  int64  \n",
      " 2   anon_id              29631 non-null  object \n",
      " 3   course_id            29631 non-null  int64  \n",
      " 4   version              29631 non-null  int64  \n",
      " 5   created_date         29631 non-null  object \n",
      " 6   text_len             29631 non-null  int64  \n",
      " 7   answer               29631 non-null  string \n",
      " 8   tokens               29631 non-null  object \n",
      " 9   tok_lem_POS          29631 non-null  object \n",
      " 10  question_type_id     29631 non-null  float64\n",
      " 11  question             29631 non-null  object \n",
      " 12  allow_text           29631 non-null  float64\n",
      " 13  gender               29631 non-null  object \n",
      " 14  L1                   29631 non-null  object \n",
      " 15  class_id             29631 non-null  object \n",
      " 16  level_id             29631 non-null  int64  \n",
      " 17  section              29631 non-null  object \n",
      " 18  MTELP_I              29631 non-null  float64\n",
      " 19  MTELP_II             29631 non-null  float64\n",
      " 20  MTELP_III            29631 non-null  float64\n",
      " 21  MTELP_Conv_Score     29631 non-null  float64\n",
      " 22  Writing_Sample       29631 non-null  float64\n",
      " 23  question_type        29631 non-null  object \n",
      " 24  num_sentences        29631 non-null  float64\n",
      " 25  avg_sentence_length  29631 non-null  float64\n",
      " 26  total_tokens         29631 non-null  float64\n",
      "dtypes: float64(10), int64(6), object(10), string(1)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "76ad7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/PELIC_compiled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
