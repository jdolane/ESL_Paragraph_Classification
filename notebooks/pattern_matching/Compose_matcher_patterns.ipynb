{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e7056f",
   "metadata": {},
   "source": [
    "# Compose Matcher Patterns\n",
    "This notebook is used to compose patterns to add the the spaCy Dependency Matcher. For the purposes of this notebook, the matcher needs to be redefined for every new pattern so that its functionality can be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c471a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import DependencyMatcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a95c82e",
   "metadata": {},
   "source": [
    "## Present Tenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5886ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I go\n",
      "Matched Phrase: He goes\n"
     ]
    }
   ],
   "source": [
    "# Present simple active\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_simple_active = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"tag\": {\"IN\": [\"VBP\", \"VBZ\"]}},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"dep\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_simple_active]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I go\",\n",
    "         \"He goes\",\n",
    "         \"He does go\",\n",
    "         \"He did go\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11673c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I do work\n",
      "Matched Phrase: He does work\n"
     ]
    }
   ],
   "source": [
    "# Present simple active with auxiliaries\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_simple_active_aux = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"tag\": \"VB\"},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": {\"IN\": [\"VBP\",\"VBZ\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_simple_active_aux]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I don't work\",\n",
    "         \"He doesn't work\",\n",
    "         \"He can't go\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c242077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: He ca go\n",
      "Matched Phrase: Can you come\n",
      "Matched Phrase: They should take\n",
      "Matched Phrase: We could try\n"
     ]
    }
   ],
   "source": [
    "# Present simple active modals\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_simple_active_modal = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"tag\": \"VB\"},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": \"MD\", \"LEMMA\": {\"NOT_IN\": ['will','would']}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_simple_active_modal]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I don't work\",\n",
    "         \"He doesn't work\",\n",
    "         \"He can't go\",\n",
    "         \"Can you come?\",\n",
    "         \"I will try\",\n",
    "         'I would make',\n",
    "         \"They should take it\",\n",
    "         \"We could try\",\n",
    "         \"They would deliver\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47325efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: It is made\n",
      "Matched Phrase: You get called\n"
     ]
    }
   ],
   "source": [
    "# Present simple passive\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_simple_passive = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": {\"IN\": [\"VBP\",\"VBZ\"]}, \"DEP\": \"auxpass\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"dep\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_simple_passive]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"It isn't made here.\",\n",
    "         \"It should be made here.\",\n",
    "         \"You get called\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18549db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: It can be made\n"
     ]
    }
   ],
   "source": [
    "# Present simple passive modal\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_simple_passive_modal = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VB\", \"DEP\": \"auxpass\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"modal\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"MD\", \"LEMMA\": {\"NOT_IN\": [\"will\",\"would\"]}}   \n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"dep\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_simple_passive_modal]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"It can be made here\",\n",
    "         \"It won't be done.\",\n",
    "         \"It could have been done.\",\n",
    "         \"It would be taken.\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b3f003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I am swimming\n",
      "Matched Phrase: He is swimming\n",
      "Matched Phrase: Lambert is cooking\n",
      "Matched Phrase: Is he driving\n",
      "Matched Phrase: He is driving\n",
      "Matched Phrase: Is he talking\n",
      "Matched Phrase: Are I talking\n"
     ]
    }
   ],
   "source": [
    "# Present continuous active\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_continuous_active = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": {\"IN\": [\"VBZ\",\"VBP\"]}, \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_continuous_active]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I am not swimming\",\n",
    "         \"He is not swimming\",\n",
    "         \"He should be swimming\",\n",
    "         \"Should he be swimming?\",\n",
    "         \"Lambert is cooking\",\n",
    "         \"Is he driving?\",\n",
    "         \"He isn't driving\",\n",
    "         \"Isn't he talking?\",\n",
    "         \"Aren't I talking?\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b2ca5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: He should be swimming\n",
      "Matched Phrase: Should he be swimming\n"
     ]
    }
   ],
   "source": [
    "# Present continuous active with modal, minus will and would\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_continuous_active_modal = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VB\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"modal\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": \"MD\", \"LEMMA\": {\"NOT_IN\": [\"will\",\"would\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_continuous_active_modal]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I am not swimming\",\n",
    "         \"He is not swimming\",\n",
    "         \"He should be swimming\",\n",
    "         \"Should he be swimming?\",\n",
    "         \"Lambert is cooking\",\n",
    "         \"Is he driving?\",\n",
    "         \"He isn't driving\",\n",
    "         \"Isn't he talking?\",\n",
    "         \"Aren't I talking?\",\n",
    "         \"He will be working\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0ff15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I 'm being called\n",
      "Matched Phrase: I 'm getting called\n"
     ]
    }
   ],
   "source": [
    "# Present continuous passive\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_continuous_passive = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_ing\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"auxpass\", \"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": {\"IN\": [\"VBP\",\"VBZ\"]}, \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_continuous_passive]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\n",
    "         \"I'm not being called\",\n",
    "    \"I'm getting called\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad496b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I should be getting called\n",
      "Matched Phrase: Should I be getting called\n",
      "Matched Phrase: I could be getting called\n"
     ]
    }
   ],
   "source": [
    "# Present continuous passive with modal\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_continuous_passive_modal = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_ing\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"auxpass\", \"TAG\": \"VBG\", \"LEMMA\": {\"IN\": [\"be\",\"getting\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": \"VB\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"modal\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": \"MD\", \"LEMMA\": {\"NOT_IN\": [\"will\",\"would\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_continuous_passive_modal]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I'm not being called\",\n",
    "         \"I should be getting called\",\n",
    "         \"Should I be getting called?\",\n",
    "         \"I will be getting called\",\n",
    "         \"I could be getting called\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "176d6cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I have arrived\n",
      "Matched Phrase: He has arrived\n",
      "Matched Phrase: He has been\n",
      "Matched Phrase: Have you been\n"
     ]
    }
   ],
   "source": [
    "# Present perfect active\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_perfect_active = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": {\"IN\": [\"VBZ\",\"VBP\"]} , \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_perfect_active]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I have arrived\",\n",
    "         \"He has arrived\",\n",
    "         \"He has already been there\",\n",
    "         \"Have you never been there before?\"\n",
    "         \"He should have arrived\",\n",
    "         \"You should have seen it\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f347b958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I should have left\n",
      "Matched Phrase: I should have left\n",
      "Matched Phrase: He should have left\n",
      "Matched Phrase: Should he have left\n"
     ]
    }
   ],
   "source": [
    "# Present perfect active with modals\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_perfect_active_modal = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VB\" , \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"modal\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": \"MD\", \"LEMMA\": {\"NOT_IN\": [\"will\",\"would\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_perfect_active_modal]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I should have left\",\n",
    "         \"I shouldn't have left\",\n",
    "         \"He should have left\",\n",
    "         \"Should he have left?\",\n",
    "         \"He has left\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbd04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: He has been banned\n",
      "Matched Phrase: Has he been banned\n",
      "Matched Phrase: I have been banned\n",
      "Matched Phrase: I have been banned\n"
     ]
    }
   ],
   "source": [
    "# Present perfect passive\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_perfect_passive = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\":\"auxpass\", \"TAG\": \"VBN\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_have\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": {\"IN\":[\"VBP\",\"VBZ\"]}, \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_perfect_passive]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"He has been banned\",\n",
    "         \"Has he been banned?\",\n",
    "         \"I have been banned.\",\n",
    "         \"I have been getting banned\",\n",
    "         \"I haven't been banned\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb6555e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I should have been banned\n",
      "Matched Phrase: Should I have been banned\n",
      "Matched Phrase: He should have been banned\n",
      "Matched Phrase: Should he have been banned\n",
      "Matched Phrase: I should have been banned\n",
      "Matched Phrase: He should have been banned\n"
     ]
    }
   ],
   "source": [
    "# Present perfect passive with modal\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_perfect_passive_modal = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\":\"auxpass\", \"TAG\": \"VBN\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_have\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VB\", \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"modal\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": \"MD\", \"LEMMA\": {\"NOT_IN\": [\"will\",\"would\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_perfect_passive_modal]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I should have been banned\",\n",
    "         \"Should I have been banned?\",\n",
    "         \"He should have been banned.\",\n",
    "         \"Should he have been banned?\",\n",
    "         \"I shouldn't have been banned.\",\n",
    "         \"He shouldn't have been banned\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538d100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: You have been studying\n",
      "Matched Phrase: Has he been studying\n",
      "Matched Phrase: I have been studying\n"
     ]
    }
   ],
   "source": [
    "# Present perfect-continuous active\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_perfect_continuous_active = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_have\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": {\"IN\": [\"VBZ\",\"VBP\"]} , \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_perfect_continuous_active]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I should have been working\",\n",
    "         \"He has been getting called.\",\n",
    "         \"You have been studying.\",\n",
    "         \"Has he been studying?\",\n",
    "         \"I haven't been studying\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ba00f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I should have been working\n",
      "Matched Phrase: I might have been working\n",
      "Matched Phrase: He might have been working\n"
     ]
    }
   ],
   "source": [
    "# Present perfect-continuous active with modals\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_perfect_continuous_active_modal = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_have\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VB\" , \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"modal\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": \"MD\", \"LEMMA\": {\"NOT_IN\": [\"will\",\"would\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_perfect_continuous_active_modal]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I should have been working\",\n",
    "         \"He has been getting called.\",\n",
    "         \"You have been studying.\",\n",
    "         \"Has he been studying?\",\n",
    "         \"I haven't been studying\",\n",
    "         \"I might have been working\",\n",
    "         \"He might have been working\",\n",
    "         \"Might they have been working?\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "667305da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: They have been getting burned\n",
      "Matched Phrase: He has been getting treated\n",
      "Matched Phrase: have they been getting burned\n",
      "Matched Phrase: Have I been getting paid\n",
      "Matched Phrase: He has been getting paid\n"
     ]
    }
   ],
   "source": [
    "# Present perfect-continuous passive\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_perfect_continuous_passive = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_ing\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"auxpass\", \"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\" , \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_have\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": {\"IN\": [\"VBZ\",\"VBP\"]} , \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_perfect_continuous_passive]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"They have been getting burned\",\n",
    "         \"He has been getting treated\",\n",
    "         \"have they been getting burned?\",\n",
    "         \"Have I been getting paid?\",\n",
    "         \"He hasn't been getting paid\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d70ee1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: He should have been getting paid\n",
      "Matched Phrase: Should she have been getting paid\n",
      "Matched Phrase: I should have been getting paid\n"
     ]
    }
   ],
   "source": [
    "# Present perfect-continuous passive with modals\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "present_perfect_continuous_passive_modal = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_ing\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"auxpass\", \"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\" , \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_have\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VB\" , \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"modal\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": \"MD\", \"LEMMA\": {\"NOT_IN\": [\"will\",\"would\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [present_perfect_continuous_passive_modal]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"He should have been getting paid\",\n",
    "         \"Should she have been getting paid?\",\n",
    "         \"I should not have been getting paid\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc083837",
   "metadata": {},
   "source": [
    "## Past Tenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "094c6062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I went\n"
     ]
    }
   ],
   "source": [
    "# Past simple active\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "past_simple_active = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBD\"},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [past_simple_active]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I went\",\n",
    "         \"I did go\",\n",
    "         \"I should try\",\n",
    "         \"Did I go?\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a41e75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I did go\n",
      "Matched Phrase: Did I go\n",
      "Matched Phrase: I did see\n",
      "Matched Phrase: Did you see\n"
     ]
    }
   ],
   "source": [
    "# Past simple active aux\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "past_simple_active_aux = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VB\"},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"aux\", \"TAG\": \"VBD\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [past_simple_active_aux]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I went\",\n",
    "         \"I did go\",\n",
    "         \"I should try\",\n",
    "         \"Did I go?\",\n",
    "         \"I didn't see it\",\n",
    "         \"Did you see it?\",\n",
    "         \"Should we try?\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1a1727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: were you raised\n",
      "Matched Phrase: I was born\n",
      "Matched Phrase: I was born\n"
     ]
    }
   ],
   "source": [
    "# Past simple passive\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "past_simple_passive = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBD\", \"DEP\": \"auxpass\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [past_simple_passive]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"Where were you raised?\",\n",
    "         \"I was born in Saskatoon\",\n",
    "         \"I wasn't born there\",\n",
    "         \"I had seen it\",\n",
    "         \"We had been removed.\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0152e586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: He was swimming\n",
      "Matched Phrase: She was swimming\n",
      "Matched Phrase: I was swimming\n",
      "Matched Phrase: I was getting\n",
      "Matched Phrase: I was working\n"
     ]
    }
   ],
   "source": [
    "# Past continuous active\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "past_continuous_active = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBD\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [past_continuous_active]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"He was swimming\",\n",
    "         \"She was swimming\",\n",
    "         \"He had been swimming\",\n",
    "         \"I wasn't swimming\",\n",
    "         \"I was getting bored\",\n",
    "         \"I was getting paid\",\n",
    "         \"While I was working\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f33517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I was getting paid\n",
      "Matched Phrase: Was he getting paid\n",
      "Matched Phrase: He was getting paid\n"
     ]
    }
   ],
   "source": [
    "# Past continuous passive\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "past_continuous_passive = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_ing\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"auxpass\", \"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBD\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [past_continuous_passive]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"He was swimming\",\n",
    "         \"She was swimming\",\n",
    "         \"He had been swimming\",\n",
    "         \"I wasn't swimming\",\n",
    "         \"I was getting bored\",\n",
    "         \"I was getting paid\",\n",
    "         \"While I was working\",\n",
    "         \"Was he getting paid?\",\n",
    "         \"He wasn't getting paid\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa9973ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I had been\n",
      "Matched Phrase: He had been\n",
      "Matched Phrase: Had he gone\n",
      "Matched Phrase: They had left\n"
     ]
    }
   ],
   "source": [
    "# Past perfect active\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "past_perfect_active = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBD\" , \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [past_perfect_active]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I had been there\",\n",
    "         \"I had been working\",\n",
    "         \"He had been there\",\n",
    "         \"Had he gone?\",\n",
    "         \"They hadn't left\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aac842cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: He had been duped\n",
      "Matched Phrase: They had been saved\n",
      "Matched Phrase: Had I been ignored\n"
     ]
    }
   ],
   "source": [
    "# Past perfect passive\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "past_perfect_passive = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\":\"auxpass\", \"TAG\": \"VBN\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_have\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBD\", \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [past_perfect_passive]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"He had been duped\",\n",
    "         \"They had been saved\",\n",
    "         \"Had I been ignored?\",\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a300b515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: I had been working\n",
      "Matched Phrase: She had been working\n"
     ]
    }
   ],
   "source": [
    "# Past perfect continuous active\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "past_perfect_continuous_active = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\", \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_have\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBD\", \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [past_perfect_continuous_active]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"I had been working a lot\",\n",
    "         \"She hadn't been working\",\n",
    "         \"Had he been studying?\"\n",
    "         \"Hadn't they been eating?\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1afdb4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Phrase: They had been getting attacked\n",
      "Matched Phrase: You had been being paid\n",
      "Matched Phrase: Had she been being paid\n"
     ]
    }
   ],
   "source": [
    "# Past perfect-continuous passive\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "past_perfect_continuous_passive = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_ing\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"auxpass\", \"TAG\": \"VBG\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_be\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBN\" , \"LEMMA\": \"be\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"aux_have\",\n",
    "        \"RIGHT_ATTRS\": {\"TAG\": \"VBD\" , \"LEMMA\": \"have\"}\n",
    "    },\n",
    "    {\n",
    "        \"REL_OP\": \">\",\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"RIGHT_ID\": \"subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubjpass\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = [past_perfect_continuous_passive]\n",
    "\n",
    "matcher.add(\"Patterns\", patterns)  # Removed the extra brackets []\n",
    "\n",
    "# Example sentences\n",
    "texts = [\"They had been getting attacked\",\n",
    "         \"You had been being paid\",\n",
    "         \"Had he been paid?\",\n",
    "         \"Had she been being paid?\"\n",
    "        ]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Apply the matcher to the example sentence\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for match_id, token_ids in matches:\n",
    "        matched_phrase = [doc[i].text for i in sorted(token_ids)]\n",
    "        print(\"Matched Phrase:\", \" \".join(matched_phrase))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
